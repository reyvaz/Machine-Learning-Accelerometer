---
title: "Machine Learning Exercise"
author: "Reynaldo"
date: "5/9/2017"
output: 
  html_document: 
    keep_md: yes
    self_contained: no
    
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, warning=FALSE, message=FALSE, cache = TRUE,
                      fig.align = 'center')
```


## Summary  
This analysis uses different machine learning algorithms on accelerometer data to predict how well individuals perform weight-lifting exercises. The dataset comes from Veloso et al., (2013) and it contains data from accelerometers on the belt, forearm, arm, and dumbbell from 6 individuals.

The participants were asked to perform one set of 10 repetitions of the unilateral dumbbell biceps curl in five different ways: according to specification (class A), throwing the elbows to the front (B), lifting the dumbbell only halfway (C), lowering the dumbbell only halfway (D), and throwing the hips to the front (E).  

The following tests different machine learning algorithms, including CART, Random Forest, and Boosted GBM to predict how well the dumbbell biceps curl were performed (variable classe in the dataset).  The best performing algorithm is a Random Forest specification with $99.4\%$ accuracy, followed by a Boosted GBM with $94.3\%$ accuracy, both in the cross-validation dataset. 

1. Necessary packages
```{r packs}
library(caret); library(dplyr); library(knitr); library(pander)
library(rpart); library(rpart.plot); library(gbm)
library(randomForest); library(ggRandomForests); library(corrplot)
```
## Data Processing  
The training dataset is available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv). And the test dataset is available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv).   

2. Data
```{r data, results = "hide"}
test  <- read.csv("pml-testing.csv")
train <- read.csv("pml-training.csv")
names(train)
str(train)
```
The original dataset contains $`r dim(train)[1]`$ observations of $`r dim(train)[2]`$ variables. Preliminary analysis found: (a) a large number of variables with near zero variability; (b) the first columns contain recording and identification data irrelevant to the prediction; and (c) a significant number of variables with less than $10\%$ of valid observations. The variables with these characteristics are thus discarded.  

3. Discard variables    
        a. discard variables with near zero variance      
        b. discard variables irrelevant to prediction, columns 1-6      
        c. discard variables with 80% NAs or more
```{r discard, results = "hide"}
nrzv  <- nearZeroVar(train)
train <- train[,-nrzv]
train <- train[, -c(1:6)]
xNAs  <- which(colMeans(is.na(train)) > .8)
train <- train[, -xNAs]
```

**Cross-validation dataset**  
Data is then split into a training dataset with 60% of observations for model training, and a testing dataset with the remaining 40% of observations for cross-validation.   

4. Split data for cross-validation
```{r split, results = "hide"}
set.seed(400)
inTrain  = createDataPartition(train$classe, p = 3/5)[[1]]
training = train[ inTrain,]
testing  = train[-inTrain,]
```

**Pre-processing**  
The training dataset now contains $`r dim(training)[1]`$ observations of $`r dim(training)[2]`$ variables, all cells with valid entries. Although correlation analysis, as seen in the figure below, shows a high correlation between a significant number of predictors, no further manual pre-processing will be performed for the remaining of the analysis. As a note, PCA decomposition was able to capture $95\%$ of the variance by reducing the number of components by over $50\%$ but accuracy was significantly compromised, while expediency gains were only minor. Because of the nature of decision trees (i.e. they can branch at equivalent splitting points) scaling or translational normalization is not necessary. Furthermore, they are also robust to correlated variates.  

```{r plotcorr, fig.width=7.5, fig.height=7.5}
par(xpd=TRUE)
corrplot.mixed(cor(training[,-length(training)]), lower="color", upper="circle", mar=c(1,1,1,1),
               tl.pos="lt", diag="n", title = "Correlation Matrix Visualization",
               order="hclust", hclust.method="complete", tl.cex = .65, tl.col ="#656565")
```

## Machine Learning Specifications  

The following will test and compare the performance of 3 different machine learning algorithms: CART, Random Forest, and Boosted GBM. 

5. First Model: Classification and Regression Tree (CART)
```{r rcart}
rpart1    <- rpart(classe ~ ., method="class", data=training)
testrpart <- predict(rpart1, newdata = testing[,-length(testing)], type = "class")
cm1       <- confusionMatrix(testing$classe, testrpart)
```

```{r plotcolor, echo = FALSE}
mycolors = list("#66b3ff", "#ff80d5", "#70db70", "#d580ff", "#ffd633")
```

```{r plot1, cache = TRUE, fig.width=10, fig.height=8, fig.align = 'center'}
rpart.plot(rpart1, main="Decision Tree (rpart)", type = 1, extra=0, cex = NULL, 
           tweak = 1, fallen.leaves = FALSE, shadow.col = "#e0e0e0", box.palette = mycolors)
```

6. Second Model: Random Forest (RF)
```{r rf, results = "hide"}
rfm     <- randomForest(training[,-length(training)], training[,length(training)], ntree = 500)
testrfm <- predict(rfm, newdata = testing[,-length(testing)])
cm2     <- confusionMatrix(testing$classe, testrfm)
```

```{r rf2, fig.width=7, echo = FALSE, fig.height=4}
plot(gg_error(rfm)) + theme_bw() + scale_y_continuous(limits=c(0,.05)) + ggtitle("OOB Error Rate (Random Forest)") + geom_line(size=.75)
vimp <- varImp(rfm); vimp <- cbind(measure = rownames(vimp), vimp)
vimp <- arrange(vimp, desc(Overall))
vimp$measure <- factor(vimp$measure, levels = vimp$measure)
ggplot(vimp[1:12,], aes(measure, Overall)) + theme_bw() +
        geom_bar(stat = "identity", fill = "#ff4d94", alpha = 0.8) +
        theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
        xlab("Measure") + 
        ggtitle("Top 12 Variables of Importance (Random Forest)")
```

7. Third Model: Boosting (GBM)
```{r gbm, results = "hide"}
gbm1      <- gbm.fit(x = training[,-length(training)], y = training[,length(training)],
                        distribution = "multinomial", verbose = FALSE, 
                        interaction.depth=5, shrinkage=0.005, n.trees = 1000)
best.iter <- gbm.perf(gbm1,method="OOB", plot.it = FALSE)
probs     <- predict(gbm1, testing[,-length(testing)], n.trees = best.iter, type = "response")
indexes   <- apply(probs, 1, which.max)
testgbm   <- colnames(probs)[indexes]
cm3       <- confusionMatrix(testing$classe, testgbm)
```


```{r gbm22, echo = FALSE, fig.width=7, fig.height=4}
vimp2 <- head(summary(gbm1, plotit = FALSE), 12)
vimp2$var <- factor(vimp2$var, levels = vimp2$var)
ggplot(vimp2, aes(var, rel.inf)) + theme_bw() +
        geom_bar(stat = "identity", fill = "#b366ff", alpha = 0.8) +
        theme(axis.text.x = element_text(angle = 30, hjust = 1)) +
        xlab("Measure") + 
        ggtitle("Top 12 Variables of Importance (GBM)")
```

## Algorithm Performance Comparison

The following are some extractions from the Confusion Matrix for each specification. These calculations were done on the cross-validation dataset and should be an unbiased estimate of out of sample performance.  

10. Performance Comparison
```{r Performance}
Accuracy <- as.numeric(c(cm1$overall[1], cm2$overall[1], cm3$overall[1]))
Kappa    <- as.numeric(c(cm1$overall[2], cm2$overall[2], cm3$overall[2]))
OOBError <- 1 - Accuracy
Results <- rbind(Accuracy, Kappa, OOBError)
colnames(Results) <- c("CART", "Random Forest", "Boosted (GBM)")
```

The calculated Accuracy rates, Kappas, and Out of Sample Error rates estimates for each specification are:  

```{r Performance2, echo = FALSE}
kable(list(Results), caption = "**Model Performance**", digits = 4)
```

Performance metrics indicate that the Random Forest is the best performing algorithm for this purpose with an accuracy rate of $`r cm2$overall[1]`$. It is followed by the GBM algorithm with an accuracy rate of $`r cm3$overall[1]`$. And last, is the CART algorithm which performed poorly compared to the other 2 with an accuracy rate of $`r cm1$overall[1]`$.   

The following reports the Confusion Matrices for the 2 best performing algorithms, and Class Specific statistics for the Random Forest specification.   



```{r CMs, echo = FALSE}
pander(cm3$table, caption = "**Confusion Matrix (GMB Model)**")
pander(cm2$table, caption = "**Confusion Matrix (Random Forest Model)**")
kable(list(t(cm2$byClass[,-c(5:7)])), caption = "**Statistics By Class (Random Forest Model)**", digits = 4)
```
  
  
## Predicting on the test Dataset  

Now I will use the 2 best performing algorithms to predict how well individuals preform the dumbbell exercises using the test dataset for submission. 

11. Transforming the test dataset in the same way as training. Then using the Random Forest model for prediction
```{r testRF}
test   <- test[,-nrzv]
test   <- test[, -c(1:6)]
test   <- test[, -xNAs]
test   <- test[,-length(test)]
testRF <- predict(rfm, newdata = test)
```

12. Using the GBM model for prediction. Compare predictions
```{r testGBM}
probs2   <- predict(gbm1, test, n.trees = best.iter, type = "response")
indexes2 <- apply(probs2, 1, which.max)
testGBM  <- as.factor(colnames(probs2)[indexes2])
answers  <- cbind.data.frame(testRF, testGBM)
identical(answers$testRF, answers$testGBM)
```

The RF and the GBM predictions are identical. The answers to be submitted are:   


```{r pred, echo = FALSE}
colnames(answers) <- c("Random Forest:", "Boosted (GBM)")
kable(list(t(answers)), caption = "**Predictions on test Dataset**")
```

## Conclusion:   
This analysis used accelerometer data to predict how well individuals perform dumbbell-lifting exercises. Three machine-learning algorithms were tested: CART, Random Forest, and Boosted GBM. The best performing algorithm was the Random Forest with $99.4\%$ accuracy, followed by the Boosted GBM with $94.3\%$ accuracy, and worst performing was the CART algorithm, which performed poorly compared to the other 2 with a $72.4\%$ accuracy. 


**Reference:**   
Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. (2013) Qualitative Activity Recognition of Weight Lifting Exercises. *Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13)* . Stuttgart, Germany: ACM SIGCHI






